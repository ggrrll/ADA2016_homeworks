{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 05 - Topic modeling\n",
    "\n",
    "_Goal_ :\n",
    "\n",
    "**We want to run topic modeling over the corpus to \"discover\" the main topics of the emails.**\n",
    "\n",
    "_Tools_ :\n",
    "\n",
    "**The tools used are :**\n",
    "\n",
    "* pandas\n",
    "* [gensim](https://radimrehurek.com/gensim/index.html)\n",
    "\n",
    "_Contents_ :\n",
    "\n",
    "* [1 - Loading data](#1---Loading-data)\n",
    "* [2 - Topic modeling](#2---Topic-modeling)\n",
    "* [3 - Tweaking the number of topics](#3---Tweaking-the-number-of-topics)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# For DataFrame pretty-printing\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place, as usual, we load the `Emails.csv` file with pandas to form a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>;H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>B6</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>Wednesday, September 12, 2012 11:52 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>05/14/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td>H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Mitchell, Andrew B</td>\n",
       "      <td>Wednesday, September 12,2012 12:44 PM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>H</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011-03-11T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber                                    MetadataSubject  \\\n",
       "0   1  C05739545                                                WOW   \n",
       "1   2  C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2   3  C05739547                                      CHRIS STEVENS   \n",
       "3   4  C05739550                         CAIRO CONDEMNATION - FINAL   \n",
       "4   5  C05739554  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "     MetadataTo       MetadataFrom  SenderPersonId           MetadataDateSent  \\\n",
       "0             H  Sullivan, Jacob J            87.0  2012-09-12T04:00:00+00:00   \n",
       "1             H                NaN             NaN  2011-03-03T05:00:00+00:00   \n",
       "2            ;H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "3             H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "4  Abedin, Huma                  H            80.0  2011-03-11T05:00:00+00:00   \n",
       "\n",
       "        MetadataDateReleased  \\\n",
       "0  2015-05-22T04:00:00+00:00   \n",
       "1  2015-05-22T04:00:00+00:00   \n",
       "2  2015-05-22T04:00:00+00:00   \n",
       "3  2015-05-22T04:00:00+00:00   \n",
       "4  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "1  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...       F-2015-04841   \n",
       "2  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...       F-2015-04841   \n",
       "3  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...       F-2015-04841   \n",
       "4  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "1                        ...                                 NaN   \n",
       "2                        ...                                  B6   \n",
       "3                        ...                                 NaN   \n",
       "4                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom         ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2       Mills, Cheryl D <MillsCD@state.gov>        Abedin, Huma   \n",
       "3       Mills, Cheryl D <MillsCD@state.gov>  Mitchell, Andrew B   \n",
       "4                                       NaN                 NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "1                                     NaN        F-2015-04841   \n",
       "2  Wednesday, September 12, 2012 11:52 AM        F-2015-04841   \n",
       "3   Wednesday, September 12,2012 12:44 PM        F-2015-04841   \n",
       "4                                     NaN        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "1          C05739546            05/13/2015              RELEASE IN PART   \n",
       "2          C05739547            05/14/2015              RELEASE IN PART   \n",
       "3          C05739550            05/13/2015              RELEASE IN PART   \n",
       "4          C05739554            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "2                                                Thx   \n",
       "3                                                NaN   \n",
       "4  H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "1  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "2  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "3  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "4  B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('hillary-clinton-emails/Emails.csv')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `ExtractedBodyText` as our raw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...\n",
       "2                                                  Thx\n",
       "4    H <hrod17@clintonemail.com>\\nFriday, March 11,...\n",
       "5    Pis print.\\n-â€¢-...-^\\nH < hrod17@clintonernail...\n",
       "7    H <hrod17@clintonemail.corn>\\nFriday, March 11...\n",
       "Name: ExtractedBodyText, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_texts = emails.ExtractedBodyText.dropna()\n",
    "raw_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data is raw, we first have to pre-process it so that our results reflect meaningful topics. To do so we simple apply the same steps as in the first assignment (tokenization, stopwords removal and stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "tokens = [nltk.word_tokenize(text) for text in raw_texts]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', '-', '--', '...', 'â€¢', \"''\", '\"\"', '``', '@', '<', '>', \"'s\"]\n",
    "stop_words.update(punctuation)\n",
    "filtered_tokens = [[t for t in tok if (t not in stop_words and len(t)>1)] for tok in tokens]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [[ps.stem(t) for t in tok] for tok in filtered_tokens]\n",
    "\n",
    "texts = [[t.lower() for t in tok] for tok in stemmed_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thx']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous command shows that some emails are probably very short and do not help for topic modeling (for example if the body is just the word \"thx\"). That's why we decide to exclude emails that contains less than a fixed number of words.\n",
    "\n",
    "*NB : Another possiblity could be to consider **threads** (ie. emails and replies) as documents instead of single emails. We do **not** follow this approach here since it is rather time consuming to link emails together.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing short emails : 6742 emails\n",
      "After removing short emails : 4256 emails\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing short emails :\", len(texts), \"emails\")\n",
    "\n",
    "threshold = 5\n",
    "long_texts = [text for text in texts if len(text) > threshold]\n",
    "\n",
    "print(\"After removing short emails :\", len(long_texts), \"emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a dictionary containing all the words in our raw corpus. Then, we build the actual corpus that will be used to do topic modeling : it is represented as a list of lists (one per document), and each inner list contains words ids (wrt. the previously built dictionary) and corresponding number of occurences in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(long_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in long_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running LDA, let's just define a helper function to print the results in a nicer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper function to print topics in a nicer way\n",
    "def print_lda_topics(lda_model, numtopics, with_probabilities=True):\n",
    "    for topic_id, topic_words in lda_model.show_topics(num_topics=numtopics, formatted=False):\n",
    "        words = list(map(lambda x: x[0], topic_words))\n",
    "        probabilities = list(map(lambda x: round(x[1],4), topic_words))\n",
    "        if with_probabilities:\n",
    "            print(\"Topic\", topic_id)\n",
    "            display(pd.DataFrame([probabilities], columns=words))\n",
    "        else:\n",
    "            print(\"Topic\", topic_id, end=' : ')\n",
    "            print(' | '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run LDA and print the resulting topics. We choose to focus on 5 topics for this first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm</th>\n",
       "      <th>offic</th>\n",
       "      <th>secretari</th>\n",
       "      <th>depart</th>\n",
       "      <th>state</th>\n",
       "      <th>room</th>\n",
       "      <th>meet</th>\n",
       "      <th>arriv</th>\n",
       "      <th>rout</th>\n",
       "      <th>confer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm   offic  secretari  depart   state    room    meet   arriv    rout  \\\n",
       "0  0.0362  0.0184     0.0184  0.0179  0.0134  0.0111  0.0106  0.0067  0.0065   \n",
       "\n",
       "   confer  \n",
       "0   0.006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>see</th>\n",
       "      <th>n't</th>\n",
       "      <th>the</th>\n",
       "      <th>would</th>\n",
       "      <th>work</th>\n",
       "      <th>know</th>\n",
       "      <th>call</th>\n",
       "      <th>state</th>\n",
       "      <th>go</th>\n",
       "      <th>also</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      see     n't     the   would    work    know    call   state      go  \\\n",
       "0  0.0059  0.0057  0.0055  0.0052  0.0052  0.0049  0.0048  0.0048  0.0048   \n",
       "\n",
       "     also  \n",
       "0  0.0046  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2010</th>\n",
       "      <th>the</th>\n",
       "      <th>state</th>\n",
       "      <th>pm</th>\n",
       "      <th>obama</th>\n",
       "      <th>new</th>\n",
       "      <th>would</th>\n",
       "      <th>american</th>\n",
       "      <th>clintonemail.com</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2010     the   state      pm   obama    new   would  american  \\\n",
       "0  0.0086  0.0075  0.0064  0.0057  0.0054  0.005  0.0048    0.0041   \n",
       "\n",
       "   clintonemail.com   said  \n",
       "0             0.004  0.004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>state</th>\n",
       "      <th>would</th>\n",
       "      <th>new</th>\n",
       "      <th>american</th>\n",
       "      <th>presid</th>\n",
       "      <th>diplomaci</th>\n",
       "      <th>obama</th>\n",
       "      <th>support</th>\n",
       "      <th>nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      the   state  would     new  american  presid  diplomaci   obama  \\\n",
       "0  0.0125  0.0052  0.005  0.0042    0.0041  0.0039     0.0038  0.0037   \n",
       "\n",
       "   support  nation  \n",
       "0   0.0037  0.0036  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm</th>\n",
       "      <th>1.4</th>\n",
       "      <th>secretari</th>\n",
       "      <th>meet</th>\n",
       "      <th>offic</th>\n",
       "      <th>call</th>\n",
       "      <th>2010</th>\n",
       "      <th>work</th>\n",
       "      <th>time</th>\n",
       "      <th>b1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm     1.4  secretari    meet   offic   call    2010    work    time  \\\n",
       "0  0.0112  0.0083     0.0082  0.0063  0.0052  0.005  0.0046  0.0044  0.0042   \n",
       "\n",
       "       b1  \n",
       "0  0.0041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "\n",
    "print_lda_topics(lda, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first example, we cannot really distinguish topics at first sight. In the following section, we try different parameters for the number of topics and discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Tweaking the number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to explore a bit the results with different number of topics for LDA. For the sake of simplicity, we don't print the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tnum_topics = 10\n",
      "Topic 0 : state | diplomaci | the | u.s. | new | unit | fco | depart | forc | secretari\n",
      "Topic 1 : 2010 | pm | re | b6 | bloomberg | am | state.gov | know | happi | want\n",
      "Topic 2 : the | state | new | would | work | need | presid | make | n't | u.s.\n",
      "Topic 3 : the | american | palin | n't | israel | would | in | like | 2010 | said\n",
      "Topic 4 : call | the | work | email | today | pleas | state.gov | need | like | if\n",
      "Topic 5 : pm | secretari | offic | depart | meet | room | state | arriv | rout | confer\n",
      "Topic 6 : n't | call | state | talk | u.s. | would | want | the | bibi | he\n",
      "Topic 7 : the | would | new | obama | support | govern | state | american | presid | said\n",
      "Topic 8 : 1.4 | pm | get | b1 | call | b6 | today | see | want | 2010\n",
      "Topic 9 : labour | the | pm | 2010 | parti | new | ed | would | miliband | david\n",
      "===============================================\n",
      "\t\tnum_topics = 20\n",
      "Topic 0 : bloomberg | go | said | get | know | last | 'm | would | the | need\n",
      "Topic 1 : state | the | new | govern | log | in | da | greek | beauti | visa\n",
      "Topic 2 : 2010 | clintonemail.com | b6 | re | hrod17 | am | state.gov | state.gov' | pm | monday\n",
      "Topic 3 : the | would | in | obama | govern | work | democrat | 2010 | nation | develop\n",
      "Topic 4 : state | madam | michael | the | 2010 | in | 'sbwhoeop | work | n't | tim\n",
      "Topic 5 : call | n't | boehner | vote | today | if | republican | still | the | go\n",
      "Topic 6 : the | state | palin | labour | new | faith | time | american | would | presid\n",
      "Topic 7 : melann | verveer | call | verveerm | decemb | depart | state.gov | am | state | 2010\n",
      "Topic 8 : pm | secretari | offic | depart | room | meet | state | arriv | rout | confer\n",
      "Topic 9 : the | state | secretari | obama | pm | meet | new | depart | presid | ratif\n",
      "Topic 10 : state | arizona | the | club | jockey | govern | depart | u.s. | secretari | time\n",
      "Topic 11 : 1.4 | b1 | b6 | in | part | releas | declassifi | b5 | birthday | lieberman\n",
      "Topic 12 : the | would | time | work | n't | think | presid | like | one | make\n",
      "Topic 13 : call | also | would | want | see | ask | n't | mtg | tomorrow | day\n",
      "Topic 14 : mr. | wonder | kosovo | n't | leahi | see | ms. | clip | dialogu | the\n",
      "Topic 15 : state | the | 2010 | unit | assist | american | secretari | presid | state.gov | govern\n",
      "Topic 16 : state | 'll | see | time | we | get | n't | no | the | want\n",
      "Topic 17 : fco | want | know | state | work | the | call | also | letter | secur\n",
      "Topic 18 : the | state | new | would | u.s. | nuclear | diplomat | support | obama | american\n",
      "Topic 19 : state | call | pm | the | depart | scroll | weekend | presid | no | also\n",
      "===============================================\n",
      "\t\tnum_topics = 30\n",
      "Topic 0 : the | n't | obama | polici | would | israel | qddr | peopl | time | world\n",
      "Topic 1 : the | state | would | american | new | obama | u.s. | presid | said | make\n",
      "Topic 2 : if | pleas | joann | travel | laszczych | need | state.gov | call | assist | govern\n",
      "Topic 3 : mtg | call | want | back | pl | 2010 | also | tonight | tomorrow | op\n",
      "Topic 4 : lona | sorri | am | call | valmoro | talk | email | ok | assist | state\n",
      "Topic 5 : labour | the | call | parti | would | new | n't | know | like | poll\n",
      "Topic 6 : call | do | fm | tomorrow | let | saw | list | know | pi | putin\n",
      "Topic 7 : netanyahu | the | american | presid | obama | parti | diplomat | would | state | new\n",
      "Topic 8 : pm | state | depart | 1.4 | secretari | meet | b1 | offic | b5 | waldorf-astoria\n",
      "Topic 9 : israel | settlement | the | isra | settler | presid | kadima | would | minist | massachusett\n",
      "Topic 10 : n't | pl | call | ask | one | 'm | kosovo | would | richard | also\n",
      "Topic 11 : 2010 | b6 | state.gov' | clintonemail.com | hrod17 | re | in | am | releas | part\n",
      "Topic 12 : bloomberg | would | the | said | camera | librari | like | compani | haiti | n't\n",
      "Topic 13 : cabl | said | call | want | see | would | last | vote | parti | n't\n",
      "Topic 14 : isra | the | israel | state | logist | govern | for | taliban | afghanistan | secretari\n",
      "Topic 15 : the | van | republican | state | democrat | hous | obama | presid | said | one\n",
      "Topic 16 : a/ | the | argentina | offic | letter | we | minist | mr. | depart | pm\n",
      "Topic 17 : the | state | conflict | work | develop | diplomat | we | diplomaci | new | would\n",
      "Topic 18 : min | eur | jill | goldberg | agre | qatar | the | sca | memori | dr\n",
      "Topic 19 : pm | secretari | offic | depart | room | meet | treati | arriv | confer | state\n",
      "Topic 20 : 'm | know | want | happi | go | call | time | thx | thank | idea\n",
      "Topic 21 : state | mod | depart | the | in | u.s. | work | fco | pool | secur\n",
      "Topic 22 : bibi | work | the | email | forward | mazen | time | we | confidenti | make\n",
      "Topic 23 : 1.4 | see | get | b1 | declassifi | would | go | monday | happi | n't\n",
      "Topic 24 : chapter | depart | state | origin | secretari | pm | messa | pant | think | the\n",
      "Topic 25 : .h | 27_09_10.docx | yep | gm | arid | person | kornblum | topper | jake.sullivan | plea\n",
      "Topic 26 : melann | verveer | ashton | fco | thank | verveerm | want | state | know | work\n",
      "Topic 27 : mr. | moscow | sent | club | jockey | would | you | thx | marriag | go\n",
      "Topic 28 : pm | 2010 | state.gov | re | fw | decemb | sullivan | cheryl | mill | clintonemail.com\n",
      "Topic 29 : senat | the | vote | time | palin | would | offic | treati | parti | obama\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "num_topics = [10, 20, 30]\n",
    "\n",
    "for n in num_topics:\n",
    "    # Print parameter choice\n",
    "    print(\"\\t\\tnum_topics =\",n)\n",
    "    \n",
    "    # Run LDA\n",
    "    lda = LdaModel(corpus, num_topics=n, id2word=dictionary)\n",
    "    # Print results\n",
    "    print_lda_topics(lda, n, with_probabilities=False)\n",
    "    \n",
    "    # Print separator\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion on the results :**\n",
    "\n",
    "Again, due to short \"words\" not excluded and to Porter stemming, this is a bit hard to read. Still, we can distinguish some topics like *Topic 11* for `num_topics = 20` which is clearly about Israeliâ€“Palestinian conflict or *Topic 2* for the same parameter which seems to be about diplomacy.\n",
    "\n",
    "However, in most cases, a lot of topics seem irrelevant. Maybe a better pre-processing would help, since there are a lot or short \"meaningless\" words left, as well as common \"communication vocabulary\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
